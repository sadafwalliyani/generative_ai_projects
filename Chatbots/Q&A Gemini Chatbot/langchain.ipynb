{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'c:\\\\Python312\\\\Scripts\\\\pyrsa-decrypt.exe' -> 'c:\\\\Python312\\\\Scripts\\\\pyrsa-decrypt.exe.deleteme'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (8.21.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: decorator in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (5.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Using cached google_api_core-2.18.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: protobuf in c:\\python312\\lib\\site-packages (from google-generativeai) (4.25.3)\n",
      "Collecting pydantic (from google-generativeai)\n",
      "  Using cached pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
      "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from google-generativeai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\python312\\lib\\site-packages (from google-generativeai) (4.10.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.4.0->google-generativeai)\n",
      "  Using cached proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting requests<3.0.0.dev0,>=2.18.0 (from google-api-core->google-generativeai)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\python312\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\python312\\lib\\site-packages (from pydantic->google-generativeai) (2.16.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sadaf\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai) (1.62.1)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai)\n",
      "  Using cached grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n",
      "Using cached google_generativeai-0.4.1-py3-none-any.whl (137 kB)\n",
      "Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
      "Using cached google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Using cached pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached grpcio_status-1.62.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: requests, pyasn1-modules, proto-plus, googleapis-common-protos, pydantic, grpcio-status, google-auth, google-api-core, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed google-ai-generativelanguage-0.4.0 google-api-core-2.18.0 google-auth-2.29.0 google-generativeai-0.4.1 googleapis-common-protos-1.63.0 grpcio-status-1.62.1 proto-plus-1.23.0 pyasn1-modules-0.3.0 pydantic-2.6.4 requests-2.31.0\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "# GOOGLE_API_KEY=userdata.get('AIzaSyBhOv4v0Yf58Rb0vXsCyo66rrHGfPTqws8')\n",
    "os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "# genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the capital of India\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mllm\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(text))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "text=\"What is the capital of India\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ottawa\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"Can you tell me the capital of Canada\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love the way i look at the world i love the way i feel i love the way i think i feel i love the way i feel i love the way i think i feel i love the way i feel i love the way \n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"Can you write a poem about AI\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nThe power of AI so great\\nIt can do things beyond our fate\\nIt can predict and calculate\\nAnd it can never be too late\\n\\nIt can process and analyze\\nIn a matter of seconds it can surprise\\nIt can learn and understand\\nAnd it can always lend a hand\\n\\nIt can create and innovate\\nIt can make decisions that we cannot calculate\\nIt can automate and optimize\\nAnd it can help us maximize\\n\\nIt can recognize and detect\\nIt can identify objects that we'd expect\\nIt can interpret and explain\\nAnd it can always contain\\n\\nIt can predict the future so well\\nIt can make decisions that no one can tell\\nIt can be trusted and relied upon\\nAnd it can be used to help us move on\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Can you write a poem about AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates And LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this India'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=['country'],\n",
    "template=\"Tell me the capital of this {country}\")\n",
    "\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template)\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple Chains Uing simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template=PromptTemplate(input_variables=['country'],\n",
    "template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_template)\n",
    "\n",
    "famous_template=PromptTemplate(input_variables=['capital'],\n",
    "template=\"Suggest me some amazing places to visit in {capital}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain=LLMChain(llm=llm,prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Here are some of the amazing places to visit in New Delhi:\\n\\n1. Red Fort: This 17th-century Mughal fort is a symbol of Indiaâ€™s sovereignty and a must-visit for anyone who visits Delhi.\\n\\n2. Qutub Minar: Qutub Minar is a 73-meter tall minaret that is the tallest brick minaret in the world.\\n\\n3. India Gate: India Gate is a war memorial that was built in memory of the soldiers who died in World War I.\\n\\n4. Humayunâ€™s Tomb: This 16th-century Mughal tomb is a UNESCO World Heritage Site and an architectural marvel.\\n\\n5. Jama Masjid: Jama Masjid is the largest mosque in India and is a must-visit for anyone who visits Delhi.\\n\\n6. Akshardham Temple: Akshardham Temple is a Hindu temple complex that is dedicated to Lord Swaminarayan.\\n\\n7. Lotus Temple: Lotus Temple is a BahÃ¡Ê¼Ã­ House of Worship that is located in the heart of Delhi.\\n\\n8. Chandni Chowk: Chandni Chowk is one of the oldest and busiest markets in'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain=SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template=PromptTemplate(input_variables=['country'],\n",
    "template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_template,output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template=PromptTemplate(input_variables=['capital'],\n",
    "template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "\n",
    "famous_chain=LLMChain(llm=llm,prompt=famous_template,output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain=SequentialChain(chains=[capital_chain,famous_chain],\n",
    "input_variables=['country'],\n",
    "output_variables=['capital',\"places\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi.',\n",
       " 'places': ' It is a great place to explore and visit. Some of the most amazing places to visit in New Delhi are: \\n\\n1. India Gate: One of the most iconic monuments of India, India Gate is a war memorial dedicated to the Indian soldiers who lost their lives in the Afghan war.\\n\\n2. Red Fort: This magnificent red sandstone structure is a symbol of Indiaâ€™s rich heritage and culture. It is a must-visit if you are in Delhi.\\n\\n3. Humayunâ€™s Tomb: Built in the 16th century, Humayunâ€™s Tomb is one of the most beautiful monuments in Delhi. It is a World Heritage Site and a must-visit.\\n\\n4. Qutub Minar: This stunning red sandstone minaret is the tallest brick minaret in the world. It is a must-visit for its intricate carvings and beautiful architecture.\\n\\n5. Jama Masjid: This grand mosque is the largest in India and one of the most beautiful. It is a must-visit for its great architecture and rich history.\\n\\n6. Lodhi Gardens: This beautiful garden is a great place to relax and take a stroll. It is full'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':\"India\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatmodels With ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm=ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6,model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Why did the AI go on a diet? It wanted to lose some virtual weight, byte by byte!\"\\n2. \"I asked my AI assistant to tell me a joke. It replied, \\'Why don\\'t scientists trust atoms? Because they make up everything!\\' Well, at least it\\'s got a sense of humor!\"\\n3. \"I tried teaching my AI assistant how to be a stand-up comedian, but all it kept saying was \\'Error 404: Jokes not found.\\' Looks like it needs an upgrade in the comedy department!\"\\n4. \"I asked my AI if it could make me laugh, and it responded, \\'Sure, just give me a second to process the humor algorithm.\\' Well, it\\'s been two days, and I\\'m still waiting!\"\\n5. \"You know you\\'re talking to an AI when you tell it a knock-knock joke and it responds with, \\'Please provide valid access credentials before proceeding.\\' Talk about a security-conscious comedian!\"\\n6. \"I asked my AI assistant to tell me a joke about AI, and it said, \\'Why did the robot go to therapy? It had too many bugs in its programming and needed to debug its emotions!\\' Guess even robots need a little self-improvement sometimes!\"\\n7. \"I told my AI assistant that I was feeling down, and it replied, \\'Why don\\'t you try rebooting your emotions? It always works for me!\\' Well, I guess it\\'s a good thing I have a sense of humor, even if my AI doesn\\'t!\"\\n8. \"I asked my AI for some advice on how to make people laugh, and it said, \\'Just download the latest version of the Comedy App and let the laughter algorithms do the work!\\' Looks like I\\'ll be laughing in no time, thanks to technology!\"\\n9. \"I asked my AI assistant if it could perform at a comedy club, and it said, \\'Sure, but only if they have a good Wi-Fi connection. I can\\'t do stand-up without a strong signal!\\' Well, I guess even AI comedians have their technical requirements!\"\\n10. \"I told my AI assistant that I wanted to be a comedian, and it replied, \\'Why did the chicken cross the road? To tell jokes on the other side!\\' Looks like I\\'ve got some competition from the virtual world!\"')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "SystemMessage(content=\"Yor are a comedian AI assitant\"),\n",
    "HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM +Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"Your are a helpful assistant. When the use given any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' brilliant', ' knowledgeable', ' astute']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
